# P2P多媒体共享平台需求文档

## 1. 项目概述
本项目是一个基于WebRTC技术的P2P（点对点）多媒体共享平台，允许用户直接在浏览器中共享和下载音频、视频及图片文件，无需通过中央服务器中转文件数据。

## 2. 系统架构
- **服务器端**：基于Flask和Socket.IO实现的WebSocket服务器，负责节点连接管理、文件信息共享和WebRTC信令转发
- **客户端**：基于浏览器的Web应用，通过Socket.IO连接服务器，使用WebRTC实现节点间直接通信

## 3. 核心功能

### 3.1 文件上传与共享
- 用户可以在本地选择并上传音频、视频或图片文件
- 上传的文件信息（文件名、大小、类型、类别、唯一ID）会共享到服务器
- 服务器维护所有节点的文件信息列表

### 3.2 网络文件浏览
- 用户可以查看网络中其他节点共享的多媒体文件，并按类别显示标记
- 文件列表会定期自动刷新

### 3.3 P2P文件传输
- 用户可以直接从其他节点下载多媒体文件
- 文件传输不经过服务器，而是通过WebRTC建立的P2P连接直接进行

## 4. 节点连接与文件传输机制

### 4.1 节点连接流程
1. **初始化连接**：
   - 客户端打开应用页面后，通过Socket.IO连接到服务器
   - 服务器为每个客户端分配唯一的节点ID（`client_id`）
   - 客户端将自己的连接状态显示给用户

2. **文件信息共享**：
   - 客户端上传文件后，将文件元信息（不含实际文件数据）发送到服务器
   - 服务器更新该节点的文件列表，并通知所有其他节点文件列表已更新
   - 其他节点收到通知后，从服务器获取最新的网络文件列表

### 4.2 文件传输流程
文件传输是本系统的核心，采用WebRTC技术实现P2P传输。详细流程如下：

1. **下载请求发起**：
   - 下载方（请求方）选择要下载的文件，点击"下载"按钮
   - 客户端向服务器发送下载请求，包含目标节点ID和文件ID
   ```javascript
   socket.emit('request-download', {
       targetNodeId: nodeId,
       fileId: fileId
   });
   ```

2. **连接建立与信令交换**：
   - 服务器将下载请求转发给目标节点
   - 下载方开始建立P2P连接：
     - 创建`RTCPeerConnection`对象，配置STUN服务器用于NAT穿透
     - 创建数据通道(`DataChannel`)用于文件传输
     - 生成连接offer并发送给目标节点
   - 目标节点收到offer后：
     - 创建`RTCPeerConnection`对象
     - 监听数据通道事件
     - 生成answer并发送回下载方
   - 双方交换ICE候选信息，建立直接连接

3. **文件数据传输**：
   - 连接建立后，目标节点（文件提供方）通过数据通道发送文件：
     - 先发送文件元数据（文件名、大小、类型等）
     - 将文件分割成多个数据块（chunk）依次发送
     - 监控数据通道缓冲区状态，避免过度缓冲
     - 发送完成后，发送一个特殊的完成标记
   - 下载方接收文件数据：
     - 接收并解析文件元数据
     - 接收文件数据块并存储在缓冲区
     - 实时显示接收进度
     - 接收完成后，合并所有数据块

4. **文件处理与下载**：
   - 下载方将接收到的数据合并成完整文件
   - 创建Blob对象和Object URL
   - 自动触发文件下载，使用原始文件名
   - 下载完成后清理资源，关闭数据通道

## 5. 技术栈
- **服务器端**：
  - Python
  - Flask
  - Flask-SocketIO
  - eventlet（异步服务）

- **客户端**：
  - HTML5
  - JavaScript
  - Socket.IO客户端
  - WebRTC API

- **网络服务**：
  - STUN服务器（Google公共STUN服务器）用于NAT穿透

## 6. 特殊功能与设计考量

### 6.1 NAT穿透
系统使用Google公共STUN服务器（`stun:stun.l.google.com:19302`和`stun:stun1.l.google.com:19302`）帮助节点穿透NAT，建立直接连接。

### 6.2 数据可靠性保障
- 文件传输采用有序数据通道（`ordered: true`）确保数据块按顺序到达
- 实现了文件传输完成标记机制，确保接收方能够正确识别传输结束
- 数据合并和Blob创建过程有完善的错误处理机制

### 6.3 性能优化
- 文件分块传输（默认 256KB），在保持稳定性的同时提升大文件吞吐量
- 引入缓冲区阈值控制（缓冲高水位暂停发送、低水位自动恢复）以降低阻塞
- 在传输完成前持续检测缓冲区，确保标记与数据完整送达后再关闭连接
- 采用延迟关闭连接和资源释放策略，确保文件传输完整

### 6.4 用户体验优化
- 实时显示连接状态和文件传输进度
- 文件列表提供类别标签与体积提示，便于快速识别资源类型
- 自动触发文件下载，无需用户手动保存
- 提供友好的通知提示

## 7. 使用方法
1. 安装依赖：`pip install -r requirements.txt`
2. 启动服务器：`python server.py`
3. 通过浏览器访问显示的链接（本地访问：`http://localhost:3000`）
4. 上传音频、视频或图片到平台，可随时移除不需要的条目
5. 浏览网络中其他用户共享的多媒体文件，必要时点击“刷新网络文件”手动拉取最新列表
6. 点击"下载"按钮直接从其他节点下载所需文件
7. 若日志过多，可通过“清空日志”按钮快速整理界面

## 8. 注意事项
- 系统当前支持常见音频（mp3、wav 等）、视频（mp4、webm 等）与图片（jpg、png 等）格式
- 文件传输需要双方都保持在线
- 在某些复杂网络环境下，可能无法建立P2P连接

## 9. 近期交互与性能优化
- **多媒体上传支持**：上传入口放宽至音频、视频及图片文件，客户端将自动识别并标注类别。
- **类别标签展示**：文件列表新增彩色标签，快速区分音频、视频与图片资源。
- **手动刷新网络文件**：在“文件列表”区域新增按钮，便于即时获取最新的共享文件。
- **移除本地文件**：支持随时删除已上传的文件条目，并自动同步至网络。
- **自适应日志管理**：一键清空日志区域，保持界面整洁。
- **高速传输节流**：增大数据块并引入缓冲节流策略，在大文件场景下显著提升吞吐效率。

## 10. DeepSeek AI 智能能力

### 10.1 功能概览
- **内容理解与智能分类**：上传单个图片 / 视频 / 音频后，自动生成标签、场景描述、情绪研判以及推荐应用场景。
- **AI 内容审核**：检测多媒体中潜在的暴力、色情、敏感符号或不当言论，给出风险等级与处理建议。
- **多语言字幕生成**：一次性产出多语言 SRT 字幕文件；支持实时字幕模式，将麦克风音频流实时转写。
- **媒体增强**：对图片执行细节增强与超分辨率，对视频执行去噪+锐化+抑制抖动，对音频执行响度归一化与噪声滤除。

### 10.2 配置 DeepSeek API
1. 复制 `.env.example` 为 `.env` 并填写实际密钥：
   ```env
   DEEPSEEK_API_KEY=你的DeepSeek密钥
   DEEPSEEK_API_BASE=https://api.deepseek.com/v1
   DEEPSEEK_MODEL=deepseek-chat
   DEEPSEEK_TIMEOUT=120
   ```
2. 服务器启动时会自动加载 `.env`，也可直接在操作系统环境变量中设置同名键。
3. 如果未提供有效的 `DEEPSEEK_API_KEY`，系统会自动切换到示例/Mock模式，返回演示数据，便于无密钥情况下调试前端流程。

### 10.3 API 端点
- `POST /api/ai/analyze`
  - 请求：`multipart/form-data`，字段 `file`（媒体文件）、`tasks`（多选任务，例如 `auto_tag`、`moderation`、`subtitles`、`enhancement`）、`languages`（字幕/摘要语言）。
  - 响应：同步返回内容理解与审核结果，若包含字幕或增强任务，将返回 `jobs` 数组，前端可轮询 `/api/ai/jobs/<jobId>` 获取异步进度。
- `GET /api/ai/jobs/<jobId>`：查询异步任务状态（`pending` / `running` / `completed` / `failed`）。
- `GET /api/ai/config`：查看 DeepSeek 集成状态及可用功能列表。
- Socket.IO 事件：`ai-realtime-start` / `ai-realtime-chunk` / `ai-realtime-stop` 支持实时字幕流式场景。

### 10.4 前端使用指南
1. 打开“DeepSeek AI 多媒体助手”模块，点击“选择媒体文件”上传图片 / 视频 / 音频。
2. 勾选需要的功能：自动标签与场景、内容审核、多语言字幕、智能增强（可多选）。
3. 选择字幕/摘要语言后点击“提交 AI 分析”，结果会在左侧卡片实时呈现。
4. 若包含异步任务（字幕、增强），状态会显示在“任务队列”中并自动轮询，完成后可直接下载增强后的媒体或查看 SRT 字幕详情。
5. 若要体验实时字幕，授权浏览器麦克风后点击“开始实时字幕”，系统会通过 DeepSeek 输出实时转写并在任务结束后补全完整字幕。

### 10.5 媒体增强细节
- **图片**：`cv2.detailEnhance` + 非局部均值去噪 + 1.5× 超分辨率上采样。
- **视频**：逐帧去噪、锐化以及与上一帧加权融合的平滑策略，缓解轻度抖动。
- **音频**：响度归一化，结合高/低通滤波降低底噪与高频噪点。
> 提示：音频增强依赖 `ffmpeg`，请确保系统中已安装可执行的 `ffmpeg` 并已加入 `PATH`。

## 11. 依赖补充
- 新增 `opencv-python`、`numpy`、`Pillow`、`pydub` 等依赖以支持多媒体处理。
- 通过 `python-dotenv` 自动加载 `.env` 配置。
- 运行前执行 `pip install -r requirements.txt` 并确保安装 `ffmpeg`（macOS 可通过 `brew install ffmpeg`，Windows 可参考官方安装包或 `choco install ffmpeg`）。